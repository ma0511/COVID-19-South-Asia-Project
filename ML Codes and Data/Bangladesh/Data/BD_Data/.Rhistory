nrow(df[df$state == "", "state"])
df[df$state == "", ]
df[df$state == "", ] <- NA
##... Remove missing data
nrow(df[complete.cases(df), ])
df <- df[complete.cases(df), ]
##... Format the date variable
df$date <- as.Date(df$date, format = "%Y-%m-%d")
##... Create the month, week, and day variables
df$month <- lubridate::month(df$date, label = TRUE, abbr = FALSE)
df$day <- lubridate::wday(df$date, label = TRUE, abbr = FALSE)
df$week <- lubridate::week(df$date)
df$year <- lubridate::year(df$date)
df$week <- factor(df$week)
df$year <- factor(df$year)
##... Arrange the data
df <- dplyr::arrange(df, state, district, date)
##... Daily Cases
df <- df %>% dplyr::group_by(district) %>%
dplyr::mutate(daily_case = c(cum_cases[1], diff(cum_cases)))
summary(df$daily_case)
df <- dplyr::filter(df, !(daily_case < 0))
summary(df$daily_case)
##... Clean the district variable
df$district <- str_trim(df$district)
##... Rename the daily case variable
df <- df %>% dplyr::rename(cases = daily_case)
##... Filter the data (select from May 2020)
# df <- df %>% dplyr::filter(date >= "2020-05-01")
###################################################
# Merge the covid-19 data with the revised CR-index
###################################################
##... Read the revised CR-index data
setwd("~/Research/Shonchoy_Covid-19/Revised_CR_Index_Jun2022")
cr.index <- haven::read_dta("India.dta")
##... See the district names
length(unique(cr.index$lgd_district_id))
##... See the district names from covid-19 data
unique(df$district)
length(unique(df$lgd_district_id))
##... Remove unwanted district names and cleaning district variable
df <- dplyr::filter(df, district != "not reported")
df$district <- gsub(pattern = "\\s+", replacement = " ", df$district)
df$district <- stringr::str_trim(df$district)
##... Merge the data
df <- merge(df, cr.index[, c("lgd_state_id", "lgd_district_id", "cr_index_india_2")], by = c("lgd_state_id", "lgd_district_id"),
all.x = TRUE)
##... Rename the variables
colnames(df)[colnames(df) == "cr_index_india_2"] <- "index"
##... Arrange the data
df <- dplyr::arrange(df, state, district, date)
#############################################################
# Predictive Performance and Model Comparison: District Level
# Training data: All 2020
# Testing data:  January 2021
#############################################################
df.ind <- df
set.seed(10)
###################
# Load the packages
###################
##... Notes
# For non-R Users
library("ggplot2")    # install.packages("ggplot2")
library("dplyr")      # install.packages("dplyr")
library("haven")      # install.packages("haven")
library("stargazer")  # install.packages("stargazer")
library("labelled")   # install.packages("labelled")
library("tidyr")      # install.packages("tidyr")
library("caret")      # install.packages("caret")
library("lubridate")  # install.packages("lubridate")
library("mlbench")    # install.packages("mlbench")
library("randomForest")
library("zoo")
library("stringr")
library("purrr")
library("MLeval")
library("scales")
########################
# User Defined Functions
########################
firstup <- function(x) {
x <- tolower(x)
substr(x, 1, 1) <- toupper(substr(x, 1, 1))
x
}
Matt_Coef <- function (conf_matrix)
{
TP <- conf_matrix$table[1,1]
TN <- conf_matrix$table[2,2]
FP <- conf_matrix$table[1,2]
FN <- conf_matrix$table[2,1]
mcc_num <- (TP*TN - FP*FN)
mcc_den <-
as.double((TP+FP))*as.double((TP+FN))*as.double((TN+FP))*as.double((TN+FN))
mcc_final <- mcc_num/sqrt(mcc_den)
return(mcc_final)
}
signature=function(x){
sig=paste(sort(unlist(strsplit(tolower(x)," "))),collapse='')
return(sig)
}
partialMatch=function(x,y,levDist=0.1){
xx=data.frame(sig=sapply(x, signature),row.names=NULL)
yy=data.frame(sig=sapply(y, signature),row.names=NULL)
xx$raw=x
yy$raw=y
xx=subset(xx,subset=(sig!=''))
xy=merge(xx,yy,by='sig',all=T)
matched=subset(xy,subset=(!(is.na(raw.x)) & !(is.na(raw.y))))
matched$pass="Duplicate"
todo=subset(xy,subset=(is.na(raw.y)),select=c(sig,raw.x))
colnames(todo)=c('sig','raw')
todo$partials= as.character(sapply(todo$sig, agrep, yy$sig,max.distance = levDist,value=T))
todo=merge(todo,yy,by.x='partials',by.y='sig')
partial.matched=subset(todo,subset=(!(is.na(raw.x)) & !(is.na(raw.y))),select=c("sig","raw.x","raw.y"))
partial.matched$pass="Partial"
matched=rbind(matched,partial.matched)
un.matched=subset(todo,subset=(is.na(raw.x)),select=c("sig","raw.x","raw.y"))
if (nrow(un.matched)>0){
un.matched$pass="Unmatched"
matched=rbind(matched,un.matched)
}
matched=subset(matched,select=c("raw.x","raw.y","pass"))
return(matched)
}
###############################
# Read the Indian covid-19 data
###############################
setwd("~/Research/Shonchoy_Covid-19")
covid.ind.old <- haven::read_dta("ML_crindex_India.dta")
setwd("~/Research/Shonchoy_Covid-19/Updated_data")
covid.ind <- haven::read_dta("covid_infected_deaths.dta")
###############################
# Select the relevant variables
###############################
df <- dplyr::select(covid.ind, date, lgd_state_name, lgd_state_id, lgd_district_name, lgd_district_id, total_cases, total_deaths)
##################
# Data Preparation
##################
##... Rename variables
df <- df %>% dplyr::rename(cum_cases = total_cases, district = lgd_district_name, state = lgd_state_name, deaths = total_deaths)
##... State Names
length(unique(df$state)); unique(df$state)
nrow(df[df$state == "", ])
nrow(df[df$state == "", "state"])
df[df$state == "", ]
df[df$state == "", ] <- NA
##... Remove missing data
nrow(df[complete.cases(df), ])
df <- df[complete.cases(df), ]
##... Format the date variable
df$date <- as.Date(df$date, format = "%Y-%m-%d")
##... Create the month, week, and day variables
df$month <- lubridate::month(df$date, label = TRUE, abbr = FALSE)
df$day <- lubridate::wday(df$date, label = TRUE, abbr = FALSE)
df$week <- lubridate::week(df$date)
df$year <- lubridate::year(df$date)
df$week <- factor(df$week)
df$year <- factor(df$year)
##... Arrange the data
df <- dplyr::arrange(df, state, district, date)
##... Daily Deaths
df <- df %>% dplyr::group_by(district) %>%
dplyr::mutate(ddeaths = c(deaths[1], diff(deaths)))
summary(df$ddeaths)
# View(df[df$ddeaths < 0, ])
# nrow(df[df$ddeaths < 0, ])
df <- dplyr::filter(df, !(ddeaths < 0))
summary(df$ddeaths)
##... Clean the district variable
df$district <- str_trim(df$district)
###################################################
# Merge the covid-19 data with the revised CR-index
###################################################
##... Read the revised CR-index data
setwd("~/Research/Shonchoy_Covid-19/Revised_CR_Index_Jun2022")
cr.index <- haven::read_dta("India.dta")
##... See the district names
length(unique(cr.index$lgd_district_id))
##... See the district names from covid-19 data
unique(df$district)
length(unique(df$lgd_district_id))
##... Remove unwanted district names and cleaning district variable
df <- dplyr::filter(df, district != "not reported")
df$district <- gsub(pattern = "\\s+", replacement = " ", df$district)
df$district <- stringr::str_trim(df$district)
##... Merge the data
df <- merge(df, cr.index[, c("lgd_state_id", "lgd_district_id", "cr_index_india_2")], by = c("lgd_state_id", "lgd_district_id"),
all.x = TRUE)
##... Rename the variables
colnames(df)[colnames(df) == "cr_index_india_2"] <- "index"
##... Arrange the data
df <- dplyr::arrange(df, state, district, date)
#############################################################
# Predictive Performance and Model Comparison: District Level
# Training data: All 2020
# Testing data:  January 2021
#############################################################
df.ind <- df
set.seed(10)
set.seed(10)
##... Data Preparation: Using year 2021 as the test
df <- df.ind
df$test <- ifelse(df$year == "2021", 1, 0)
df1 <- df %>%
dplyr::group_by(district, test) %>%
dplyr::summarise(deaths_dist = sum(ddeaths, na.rm = TRUE),
index = unique(index))
df1 <- df1 %>% dplyr::group_by(test) %>% dplyr::mutate(total_deaths = sum(deaths_dist))
df1 <- df1 %>% dplyr::mutate(deaths_pct = (deaths_dist/total_deaths) * 100)
df1$death_cat <- with(df1, ave(deaths_pct, c("district", "test"), FUN = function(x) ifelse(x >= quantile(x = deaths_pct, probs = 0.75),
"V.High", ifelse(x > quantile(x = deaths_pct, probs = 0.25) & x < quantile(x = deaths_pct, probs = 0.75), "Average","Low"))))
df1$death_cat <- factor(df1$death_cat)
##... Model Performance : Using year 2021 as the test
control <- trainControl(method = "repeatedcv", number = 5, repeats = 50, search = "random", sampling = "up")
df1.train <- df1[df1$test == 0, ]
df1.test <- df1[df1$test == 1, ]
rf.cv <- train(death_cat ~ index,
data = df1.train,
method = 'rf',
trControl = control)
rf.pred <- predict(rf.cv , df1.test)
rf.cm <- caret::confusionMatrix(rf.pred, df1.test$death_cat)
rf.cm
mean(rf.cm$byClass[,"Balanced Accuracy"])
mean(rf.cm$byClass[,"Sensitivity"])
mean(rf.cm$byClass[,"Specificity"])
pred <- predict(rf.cv, df1.test)
result <- pROC::multiclass.roc(df1.test$death_cat, as.numeric(pred))
result
pred <- predict(rf.cv, df1.test, type = "prob")
pROC::multiclass.roc(df1.test$death_cat, pred)
###################
# Load the packages
###################
# For non-R Users
library("ggplot2")    # install.packages("ggplot2")
library("dplyr")      # install.packages("dplyr")
library("haven")      # install.packages("haven")
library("stargazer")  # install.packages("stargazer")
library("labelled")   # install.packages("labelled")
library("tidyr")      # install.packages("tidyr")
library("caret")      # install.packages("caret")
library("lubridate")  # install.packages("lubridate")
library("mlbench")    # install.packages("mlbench")
library("randomForest")
library("zoo")
library("stringr")
library("purrr")
library("MLeval")
library("scales")
library("yardstick")
########################
# User Defined Functions
########################
firstup <- function(x) {
x <- tolower(x)
substr(x, 1, 1) <- toupper(substr(x, 1, 1))
x
}
Matt_Coef <- function (conf_matrix)
{
TP <- conf_matrix$table[1,1]
TN <- conf_matrix$table[2,2]
FP <- conf_matrix$table[1,2]
FN <- conf_matrix$table[2,1]
mcc_num <- (TP*TN - FP*FN)
mcc_den <-
as.double((TP+FP))*as.double((TP+FN))*as.double((TN+FP))*as.double((TN+FN))
mcc_final <- mcc_num/sqrt(mcc_den)
return(mcc_final)
}
signature=function(x){
sig=paste(sort(unlist(strsplit(tolower(x)," "))),collapse='')
return(sig)
}
partialMatch=function(x,y,levDist=0.1){
xx=data.frame(sig=sapply(x, signature),row.names=NULL)
yy=data.frame(sig=sapply(y, signature),row.names=NULL)
xx$raw=x
yy$raw=y
xx=subset(xx,subset=(sig!=''))
xy=merge(xx,yy,by='sig',all=T)
matched=subset(xy,subset=(!(is.na(raw.x)) & !(is.na(raw.y))))
matched$pass="Duplicate"
todo=subset(xy,subset=(is.na(raw.y)),select=c(sig,raw.x))
colnames(todo)=c('sig','raw')
todo$partials= as.character(sapply(todo$sig, agrep, yy$sig,max.distance = levDist,value=T))
todo=merge(todo,yy,by.x='partials',by.y='sig')
partial.matched=subset(todo,subset=(!(is.na(raw.x)) & !(is.na(raw.y))),select=c("sig","raw.x","raw.y"))
partial.matched$pass="Partial"
matched=rbind(matched,partial.matched)
un.matched=subset(todo,subset=(is.na(raw.x)),select=c("sig","raw.x","raw.y"))
if (nrow(un.matched)>0){
un.matched$pass="Unmatched"
matched=rbind(matched,un.matched)
}
matched=subset(matched,select=c("raw.x","raw.y","pass"))
return(matched)
}
################################
# Read the revised CR index data
################################
setwd("C:/Users/User/Documents/Research/Shonchoy_Covid-19/Revised_CR_Index_Jun2022")
bd.index <- haven::read_dta("Bangladesh.dta")
# Number of unique districts
unique(bd.index$district)
# Select the relevant variables
bd.index <- dplyr::select(bd.index, district, index_a)
# Clean the district variable
bd.index$district <- str_trim(bd.index$district)
####################################
# Read the updated the covid-19 data
####################################
setwd("C:/Users/User/Documents/Research/Shonchoy_Covid-19/Updated_Data/BD_Data")
file.list <- list.files(pattern = '*.csv')
file.list <- setNames(file.list, file.list) # only needed when you need an id-column with the file-names
df <- purrr::map_df(file.list, read.csv, .id = "id")
#########################
# Clean the covid-19 data
#########################
colnames(df)[c(1, 3)] <- c("district", "cases")
df$district <- gsub(pattern = "\\.csv", "", df$district)
df$district <- str_trim(df$district)
df <- df %>% tidyr::separate(Category, c("month_", "day_"), sep = "-")
df$day_ <- as.numeric(df$day_)
df$Year <- as.integer(df$Year)
colnames(df)[colnames(df) == "Year"] <- "year"
##... Date Variable
df$date_str <- paste(df$month_, df$day_, df$year, sep = "-")
df$date <- as.Date(df$date_str, format = "%B-%d-%Y")
##... Fill in the missing date variable.
df <- df %>%
dplyr::group_by(district) %>%
dplyr::mutate(date = as.Date(date)) %>%
tidyr::complete(date = seq.Date(min(date), max(date), by = "day"))
##... Arrange the data by district and date
df <- dplyr::arrange(df, district, date)
##... Convert missing cases to 0
df[is.na(df$cases), "cases"] <- 0
##... Drop unwanted variables
df <- dplyr::select(df, -day_, -month_, -year, -date_str)
##... Add month, day, and week variables
df$day <- lubridate::wday(df$date, label = TRUE, abbr = FALSE)
df$week <- lubridate::week(df$date)
df$month <- lubridate::month(df$date, label = TRUE, abbr = FALSE)
df$year <- lubridate::year(df$date)
##... District Names
unique(bd.index$district)
unique(df$district)
unique(bd.index$district)[!(unique(bd.index$district) %in% unique(df$district))]
df[which(df$district == "Nowabganj"), "district"] <- "Chapainawabganj"
df[which(df$district == "Jhalakati"), "district"] <- "Jhalokati"
df[which(df$district == "Noagoan"), "district"] <- "Naogaon"
df[which(df$district == "Narsingdhi"), "district"] <- "Narsingdi"
df[which(df$district == "Panchagharh"), "district"] <- "Panchagarh"
df[which(df$district == "Perojpur"), "district"] <- "Pirojpur"
df[which(df$district == "Sariatpur"), "district"] <- "Shariatpur"
df[which(df$district == "Thakurgoan"), "district"] <- "Thakurgaon"
bd.index[which(bd.index$district == "Maulvibazar"), "district"] <- "Moulvi Bazar"
bd.index[which(bd.index$district == "Gaibandah"), "district"] <- "Gaibandha"
bd.index[which(bd.index$district == "CHAPAI NABABGANJ"), "district"] <- "Chapainawabganj"
bd.index[which(bd.index$district == "SIRAJGANJ"), "district"] <- "Sirajganj"
bd.index[which(bd.index$district == "Khagrachhari"), "district"] <- "Khagrachari"
df <- dplyr::arrange(df, district, date)
##... Merge the variables
df.21 <- merge(df, bd.index[, c("district", "index_a")], by = "district", all.x = TRUE)
#############################################################
# Predictive Performance and Model Comparison: District Level
# Training data: All 2020
# Testing data:  January 2021
#############################################################
set.seed(10)
#############################################################
# Predictive Performance and Model Comparison: District Level
# Training data: All 2020
# Testing data:  All 2021
#############################################################
set.seed(10)
##... Data Preparation: Using year 2021 as the test
df <- df.21
df <- dplyr::filter(df, year %in% c(2020, 2021))
df$test <- ifelse(df$year == 2021, 1, 0)
df1 <- df %>%
dplyr::group_by(district, test) %>%
dplyr::summarise(cases_dist = sum(cases, na.rm = TRUE),
index = unique(index_a))
df1 <- df1 %>% dplyr::group_by(test) %>% dplyr::mutate(total_cases = sum(cases_dist))
df1 <- df1 %>% dplyr::mutate(cases_pct = (cases_dist/total_cases) * 100)
df1$percentile_25 <- quantile(df1$index, probs = 0.25)
df1$percentile_90 <- quantile(df1$index, probs = 0.90)
df1$case_cat <- with(df1, ave(cases_pct, c("district", "test"), FUN = function(x) ifelse(x >= quantile(x = cases_pct, probs = 0.90),
"Red", ifelse(x >= quantile(x = cases_pct, probs = 0.25) & x < quantile(x = cases_pct, probs = 0.90), "Orange","Green"))))
df1$case_cat <- factor(df1$case_cat)
df1$case_cat <- relevel(df1$case_cat, ref = "Red")
##... Model Performance : Using year 2021 as the test
control <- trainControl(method = "repeatedcv", number = 5, repeats = 50, search = "random", sampling = "up")
df1.train <- df1[df1$test == 0, ]
df1.test <- df1[df1$test == 1, ]
rf.cv <- train(case_cat ~ index,
data = df1.train,
method = 'rf',
trControl = control)
rf.pred <- predict(rf.cv , df1.test)
rf.cm <- caret::confusionMatrix(rf.pred, df1.test$case_cat)
rf.cm
mean(rf.cm$byClass[,"Balanced Accuracy"])
mean(rf.cm$byClass[,"Sensitivity"])
mean(rf.cm$byClass[,"Specificity"])
##... ROC - AUC
pred <- predict(rf.cv, df1.test, type = "prob")
pROC::multiclass.roc(df1.test$case_cat, pred)
pred <- predict(rf.cv, df1.test)
result <- pROC::multiclass.roc(df1.test$case_cat, as.numeric(pred))
result
plot.roc(result$rocs[[1]],
print.auc=T,
legacy.axes = T)
plot.roc(result$rocs[[2]],
add=T, col = 'red',
print.auc = T,
legacy.axes = T,
print.auc.adj = c(0,3))
plot.roc(result$rocs[[3]],add=T, col = 'blue',
print.auc=T,
legacy.axes = T,
print.auc.adj = c(0,5))
legend('bottomright',
legend = c('Red-Green',
'Red-Orange',
'Green-Orange'),
col=c('black','red','blue'),lwd=2)
set.seed(10)
##... Data Preparation: Using February 2022 as the test
df <- dplyr::filter(df.21, date >= "2020-01-01" & date <= "2022-02-28")
df <- dplyr::filter(df, !(month %in% c("January", "February", "March", "April", "May", "June", "July", "August", "September",
"October", "November", "December") & year == 2021))
df <- dplyr::filter(df, !(month %in% c("January") & year == 2022))
df$test <- ifelse(df$date >= "2022-02-01" & df$date <= "2022-02-28", 1, 0)
df1 <- df %>%
dplyr::group_by(district, test) %>%
dplyr::summarise(cases_dist = sum(cases, na.rm = TRUE),
index = unique(index_a))
df1 <- df1 %>% dplyr::group_by(test) %>% dplyr::mutate(total_cases = sum(cases_dist))
df1 <- df1 %>% dplyr::mutate(cases_pct = (cases_dist/total_cases) * 100)
df1$percentile_25 <- quantile(df1$index, probs = 0.25)
df1$percentile_90 <- quantile(df1$index, probs = 0.90)
df1$case_cat <- with(df1, ave(cases_pct, c("district", "test"), FUN = function(x) ifelse(x >= quantile(x = cases_pct, probs = 0.90),
"Red", ifelse(x >= quantile(x = cases_pct, probs = 0.25) & x < quantile(x = cases_pct, probs = 0.90), "Orange","Green"))))
df1$case_cat <- factor(df1$case_cat)
df1$case_cat <- relevel(df1$case_cat, ref = "Red")
##... Model Performance : Using February 2022 as the test
control <- trainControl(method = "repeatedcv", number = 5, repeats = 50, search = "random", sampling = "up")
df1.train <- df1[df1$test == 0, ]
df1.test <- df1[df1$test == 1, ]
rf.cv <- train(case_cat ~ index,
data = df1.train,
method = 'rf',
trControl = control)
rf.pred <- predict(rf.cv , df1.test)
rf.cm <- caret::confusionMatrix(rf.pred, df1.test$case_cat)
rf.cm
mean(rf.cm$byClass[,"Balanced Accuracy"])
mean(rf.cm$byClass[,"Sensitivity"])
mean(rf.cm$byClass[,"Specificity"])
##... ROC - AUC
pred <- predict(rf.cv, df1.test, type = "prob")
pROC::multiclass.roc(df1.test$case_cat, pred)
pred <- predict(rf.cv, df1.test)
pROC::multiclass.roc(df1.test$case_cat, pred)
pROC::multiclass.roc(df1.test$case_cat, as.numeric(pred))
pred <- predict(rf.cv, df1.test, type = "prob")
pROC::multiclass.roc(df1.test$case_cat, pred)
class(pred)
pred <- as.ordered(pred)
pROC::multiclass.roc(df1.test$case_cat, pred)
pred <- predict(rf.cv, df1.test, type = "prob")
pROC::multiclass.roc(df1.test$case_cat, pred)
View(pred)
pred <- predict(rf.cv, df1.test)
pROC::multiclass.roc(df1.test$case_cat, pred)
data(aSAH)
str(aSAH)
aSAH$s100b
aSAH$gos6
multiclass.roc(aSAH$gos6, aSAH$s100b, levels=c(3, 4, 5))
multiclass.roc(aSAH$gos6, aSAH$s100b, percent=TRUE)
requireNamespace("nnet")
data(iris)
iris.sample <- sample(1:150)
iris.train <- iris[iris.sample[1:75],]
iris.test <- iris[iris.sample[76:150],]
mn.net <- nnet::multinom(Species ~ ., iris.train)
# Use predict with type="prob" to get class probabilities
iris.predictions <- predict(mn.net, newdata=iris.test, type="prob")
head(iris.predictions)
# This can be used directly in multiclass.roc:
multiclass.roc(iris.test$Species, iris.predictions)
iris.test$Species
mn.net
result <- multiclass.roc(iris.test$Species, iris.predictions)
result
result$rocs$`setosa/versicolor`
result$rocs
# Select only 3 of the aSAH$gos6 levels:
multiclass.roc(aSAH$gos6, aSAH$s100b)
multiclass.roc(aSAH$gos6, aSAH$s100b, percent=TRUE)
multiclass.roc(aSAH$gos6, aSAH$s100b, percent=TRUE)
result <- multiclass.roc(iris.test$Species, iris.predictions)
result
2.65 + 2.80 + 3.15 + 3.70 + 2.49 + 0.99 + 2.10
